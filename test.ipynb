{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DATA/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'tech', 'politics', 'sport', 'entertainment'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "\n",
    "# Loading stopwords from nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Function for text preprocessing\n",
    "def txt_preprocessing(total_text, index, column, df):\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        # Replace every special character with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n",
    "        # Remove multiple spaces\n",
    "        total_text = re.sub('\\s+',' ', total_text)\n",
    "        # Converting to lowercase\n",
    "        total_text = total_text.lower()\n",
    "        \n",
    "        for word in total_text.split():\n",
    "        # If word is not a stopword then retain that word from the data\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        df[column][index] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens maj...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses 168m payout eighteen former enron...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens maj...  business\n",
       "3       1976  lifestyle governs mobile choice faster better ...      tech\n",
       "4        917  enron bosses 168m payout eighteen former enron...  business"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if type(row['Text']) is str:\n",
    "        txt_preprocessing(row['Text'], index, 'Text', data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_data size -> (149, 3)\n",
      "Testing_data size -> (30, 3)\n"
     ]
    }
   ],
   "source": [
    "ind = list(data.index)\n",
    "# np.random.shuffle(ind)\n",
    "\n",
    "train_len = int(data.shape[0]*0.1)\n",
    "train_ind = ind[:train_len]\n",
    "training_data = data.iloc[train_ind,:]\n",
    "# training_data.head()\n",
    "\n",
    "# test_ind = ind[train_len:]\n",
    "# testing_data = data.iloc[test_ind,:]\n",
    "test_ind = ind[150:180]\n",
    "testing_data = data.iloc[test_ind,:]\n",
    "#testing_data.head()\n",
    "\n",
    "print('Training_data size -> {}'.format(training_data.shape))\n",
    "print('Testing_data size -> {}'.format(testing_data.shape))\n",
    "\n",
    "# assert data.shape[0] ==  len(train_ind)+ len(test_ind), 'Not equal distribution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, target, dataframe):\n",
    "        self.df = dataframe\n",
    "        # Target/Category Column\n",
    "        self.c_n = target\n",
    "        # Column Names\n",
    "        self.cols = list(self.df.columns)\n",
    "        self.cols.remove(self.c_n)\n",
    "        \n",
    "        self.store = {}\n",
    "        self.likelihood_for_all_()\n",
    "        \n",
    "    def likelihood_cal(self, x, y, z):\n",
    "        \"\"\" \n",
    "        x -> Column Name (String)\n",
    "        y -> Column Value (String)\n",
    "        z -> Class value (String)\n",
    "        c_n -> Class Name (Target)\n",
    "        \n",
    "        Returns -> P(x = y | c_n = z)\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        \n",
    "        if x not in self.cols:\n",
    "            raise KeyError(\"Feature(column) not present in the Training Dataset\")\n",
    "        \n",
    "        res =  len(df[(df[x] == y) & (df[self.c_n] == z)]) /len(df[df[self.c_n] == z])\n",
    "        \n",
    "        if res == 0.0:\n",
    "            return 1/(len(df[df[self.c_n] == z]) + len(df[x].unique()))\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def likelihood_for_all_(self):     \n",
    "        df = self.df\n",
    "        \n",
    "        dict1 = {}\n",
    "        for x in self.cols:\n",
    "            dict2 = {}\n",
    "            for y in df[x].unique():\n",
    "                dict3 = {}\n",
    "                for z in df[self.c_n].unique():\n",
    "                    #print('P({}=\"{}\"|{}=\"{}\") = {}'.format(x,y,self.c_n,z,self.likelihood_cal(x, y, z)))\n",
    "                    dict3[z] = self.likelihood_cal(x, y, z)\n",
    "                dict2[y] = dict3\n",
    "            dict1[x] = dict2\n",
    "        \n",
    "        self.store = dict1\n",
    "    \n",
    "    def likelihood_expr(self, class_val, expr):\n",
    "        val = 1  \n",
    "        \n",
    "        for k,v in expr:\n",
    "            try:\n",
    "                store_val = self.store[k][v][class_val]\n",
    "            except:\n",
    "                store_val = self.likelihood_cal(k,v,class_val)\n",
    "                \n",
    "            val *= store_val\n",
    "                                         \n",
    "        return val\n",
    "    \n",
    "    def prior(self, class_val):\n",
    "        df = self.df\n",
    "        return len(df[df[self.c_n] == class_val])/df.shape[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        df = self.df\n",
    "        \n",
    "        if type(X) == pd.core.series.Series:\n",
    "            values_list = [list(X.items())]\n",
    "            \n",
    "        elif type(X) == pd.core.frame.DataFrame:\n",
    "            values_list = [list(y.items()) for x,y in X.iterrows()]\n",
    "            \n",
    "        else:\n",
    "            raise TypeError('{} is not supported type'.format(type(X)))\n",
    "            \n",
    "        \n",
    "        predictions_list = []\n",
    "        for values in values_list:\n",
    "            likelihood_priors = {}\n",
    "            for class_val in df[self.c_n].unique():\n",
    "                likelihood_priors[class_val] = self.prior(class_val)*self.likelihood_expr(class_val,values)\n",
    "            #print(likelihood_priors)\n",
    "            \n",
    "            normalizing_prob = np.sum([x for x in likelihood_priors.values()])\n",
    "            probabilities = [(y/normalizing_prob,x) for x,y in likelihood_priors.items()]\n",
    "           \n",
    "            \n",
    "            if len(probabilities) == 2:\n",
    "                # For 2 Class Predictions\n",
    "                max_prob = max(probabilities)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "            \n",
    "            else:\n",
    "                # For Mulit Class Predictions\n",
    "                exp_1 = [np.exp(x) for x,y in probabilities]\n",
    "                exp_2 = np.sum(exp_1)\n",
    "                softmax = exp_1/exp_2\n",
    "                #print(softmax)\n",
    "                class_names = [y for x,y in probabilities]\n",
    "                softmax_values = [(x,y) for x,y in zip(softmax,class_names)]\n",
    "                #print(softmax_values)\n",
    "                max_prob = max(softmax_values)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "        \n",
    "        print(probabilities)\n",
    "        return predictions_list\n",
    "    \n",
    "    def accuracy_score(self, X, Y):\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        total_matching_values = [x == y for x,y in zip(X,Y)]\n",
    "        return (np.sum(total_matching_values)/len(total_matching_values))*100\n",
    "    \n",
    "    def calculate_confusion_matrix(self, X, Y):\n",
    "        df = self.df\n",
    "        \n",
    "        unique_class_values = df[self.c_n].unique()\n",
    "        decimal_class_values = list(range(len(unique_class_values)))\n",
    "        numerical = {x:y for x,y in zip(unique_class_values, decimal_class_values)}\n",
    "        \n",
    "        x = [numerical[x] for x in X]\n",
    "        y = [numerical[y] for y in Y]\n",
    "        \n",
    "        \n",
    "        n = len(decimal_class_values)\n",
    "        confusion_matrix = np.zeros((n,n))\n",
    "        \n",
    "        for i,j in zip(x,y):\n",
    "            if i == j:\n",
    "                confusion_matrix[i][i] += 1\n",
    "            elif i != j:\n",
    "                confusion_matrix[i][j] += 1\n",
    "        \n",
    "        return confusion_matrix\n",
    "            \n",
    "    \n",
    "    def precision_score(self, X, Y):\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fp = confusion_matrix[1][0]\n",
    "        \n",
    "        return tp / (tp+fp)\n",
    "    \n",
    "    def recall_score(self, X, Y):\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fn = confusion_matrix[0][1]\n",
    "        \n",
    "        return tp / (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "genx = NB(target='Category',dataframe=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.25186479181230315, 'business'), (0.1862566554835738, 'tech'), (0.15620224605423388, 'politics'), (0.2619937672455105, 'sport'), (0.14368253940437867, 'entertainment')]\n",
      "['sport', 'sport', 'politics', 'politics', 'tech', 'business', 'business', 'entertainment', 'tech', 'entertainment', 'politics', 'tech', 'entertainment', 'sport', 'business', 'politics', 'entertainment', 'sport', 'politics', 'sport']\n",
      "['sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport']\n",
      "Accuracy Score -> 25.0 %\n"
     ]
    }
   ],
   "source": [
    "y_test = list(testing_data.iloc[0:20,2])\n",
    "\n",
    "y_pred = genx.predict(testing_data.iloc[0:20, 0:1])\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print('Accuracy Score -> {} %'.format(round(genx.accuracy_score(y_test,y_pred),3)))\n",
    "# print('Precison Score -> {}'.format(round(genx.precision_score(y_test,y_pred),3)))\n",
    "# print('Recall Score -> {}'.format(round(genx.recall_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "666cc40e7ce6d31c1437a93e07d5e72f3187b89406f08fe2ceec683eb8bf1832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
